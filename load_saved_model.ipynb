{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Loaded ensemble configuration\n",
            "Version: 1.0\n",
            "Created: 2025-10-07T11:31:00.928168\n",
            "Description: Multimodal medical prediction ensemble combining symptom analysis, heart disease prediction, and chest X-ray analysis\n",
            "#Labels: 24\n"
          ]
        }
      ],
      "source": [
        "# Load saved ensemble configuration and component models\n",
        "import os\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "CONFIG_PATH = os.path.join(\"saved_models\", \"ensemble_config_complete.pkl\")\n",
        "\n",
        "if not os.path.exists(CONFIG_PATH):\n",
        "    raise FileNotFoundError(f\"Ensemble config not found at {CONFIG_PATH}. Run the save step first in combined_model.ipynb.\")\n",
        "\n",
        "with open(CONFIG_PATH, \"rb\") as f:\n",
        "    ensemble_config = pickle.load(f)\n",
        "\n",
        "print(\"‚úÖ Loaded ensemble configuration\")\n",
        "print(f\"Version: {ensemble_config.get('version')}\")\n",
        "print(f\"Created: {ensemble_config.get('created_at')}\")\n",
        "print(f\"Description: {ensemble_config.get('description')}\")\n",
        "print(f\"#Labels: {len(ensemble_config.get('label_names', []))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading all saved models and components...\n",
            "‚úÖ Heart disease model loaded\n",
            "‚úÖ Heart scaler loaded\n",
            "‚úÖ Heart feature columns loaded\n",
            "‚úÖ Symptom model loaded\n",
            "‚úÖ TF-IDF vectorizer loaded\n",
            "‚úÖ X-ray model state dict loaded\n",
            "‚úÖ Label names loaded: 24 classes\n",
            "\n",
            "üéâ Model loading completed!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\swastik dasgupta\\anaconda3\\envs\\nltk_env\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.4.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "c:\\Users\\swastik dasgupta\\anaconda3\\envs\\nltk_env\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.4.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "c:\\Users\\swastik dasgupta\\anaconda3\\envs\\nltk_env\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.4.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "c:\\Users\\swastik dasgupta\\anaconda3\\envs\\nltk_env\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.4.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# üß† Load All Saved Models and Components\n",
        "# ============================================\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "print(\"Loading all saved models and components...\")\n",
        "\n",
        "# Load heart disease model and components\n",
        "try:\n",
        "    with open(\"heart_disease_model.pkl\", \"rb\") as f:\n",
        "        heart_model = pickle.load(f)\n",
        "    print(\"‚úÖ Heart disease model loaded\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå Heart disease model not found\")\n",
        "    heart_model = None\n",
        "\n",
        "try:\n",
        "    with open(\"heart_scaler_final.pkl\", \"rb\") as f:\n",
        "        heart_scaler = pickle.load(f)\n",
        "    print(\"‚úÖ Heart scaler loaded\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå Heart scaler not found\")\n",
        "    heart_scaler = None\n",
        "\n",
        "try:\n",
        "    with open(\"heart_feature_columns.pkl\", \"rb\") as f:\n",
        "        heart_feature_cols = pickle.load(f)\n",
        "    print(\"‚úÖ Heart feature columns loaded\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå Heart feature columns not found\")\n",
        "    heart_feature_cols = None\n",
        "\n",
        "# Load NLP model and vectorizer\n",
        "try:\n",
        "    with open(\"symptos2disease_model_fixed.pkl\", \"rb\") as f:\n",
        "        symptom_model = pickle.load(f)\n",
        "    print(\"‚úÖ Symptom model loaded\")\n",
        "except FileNotFoundError:\n",
        "    try:\n",
        "        with open(\"symptos2disease_model.pkl\", \"rb\") as f:\n",
        "            symptom_model = pickle.load(f)\n",
        "        print(\"‚úÖ Symptom model loaded (original)\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"‚ùå Symptom model not found\")\n",
        "        symptom_model = None\n",
        "\n",
        "try:\n",
        "    with open(\"tfidf_vectorizer_fixed.pkl\", \"rb\") as f:\n",
        "        tfidf_vectorizer = pickle.load(f)\n",
        "    print(\"‚úÖ TF-IDF vectorizer loaded\")\n",
        "except FileNotFoundError:\n",
        "    try:\n",
        "        with open(\"tfidf_vectorizer.pkl\", \"rb\") as f:\n",
        "            tfidf_vectorizer = pickle.load(f)\n",
        "        print(\"‚úÖ TF-IDF vectorizer loaded (original)\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"‚ùå TF-IDF vectorizer not found\")\n",
        "        tfidf_vectorizer = None\n",
        "\n",
        "# Load X-ray model\n",
        "try:\n",
        "    xray_state_dict = torch.load(\"chest_xray_cnn.pth\", map_location='cpu')\n",
        "    print(\"‚úÖ X-ray model state dict loaded\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå X-ray model not found\")\n",
        "    xray_state_dict = None\n",
        "\n",
        "# Get label names from ensemble config\n",
        "label_names = ensemble_config.get('label_names', [])\n",
        "print(f\"‚úÖ Label names loaded: {len(label_names)} classes\")\n",
        "\n",
        "print(\"\\nüéâ Model loading completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Symptom prediction function defined\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# üß† Symptom Prediction Function\n",
        "# ============================================\n",
        "\n",
        "def predict_symptoms(symptom_texts):\n",
        "    \"\"\"\n",
        "    Predicts disease from symptom text using the trained NLP model.\n",
        "    \"\"\"\n",
        "    if symptom_model is None or tfidf_vectorizer is None:\n",
        "        print(\"‚ùå Symptom model or vectorizer not loaded\")\n",
        "        return np.array([[0.0] * len(label_names)])\n",
        "    \n",
        "    # Preprocess the input text\n",
        "    def preprocess_text(text):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'\\d+', ' ', text)\n",
        "        \n",
        "        # Tokenize and remove stopwords\n",
        "        tokens = word_tokenize(text)\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        tokens = [word for word in tokens if word not in stop_words]\n",
        "        \n",
        "        # Lemmatize\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "        \n",
        "        return ' '.join(tokens)\n",
        "    \n",
        "    # Preprocess input texts\n",
        "    processed_texts = [preprocess_text(text) for text in symptom_texts]\n",
        "    \n",
        "    # Transform using the trained vectorizer\n",
        "    X_transformed = tfidf_vectorizer.transform(processed_texts)\n",
        "    \n",
        "    # Get predictions\n",
        "    predictions = symptom_model.predict(X_transformed)\n",
        "    probabilities = symptom_model.predict_proba(X_transformed)\n",
        "    \n",
        "    return probabilities\n",
        "\n",
        "print(\"‚úÖ Symptom prediction function defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Heart disease prediction function defined\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# ‚ù§Ô∏è Heart Disease Prediction Function\n",
        "# ============================================\n",
        "\n",
        "def predict_heart(input_data):\n",
        "    \"\"\"\n",
        "    Predicts heart disease probability from a single row or CSV file.\n",
        "    Accepts either a DataFrame (single/multiple rows) or a CSV path.\n",
        "    \"\"\"\n",
        "    if heart_model is None or heart_scaler is None or heart_feature_cols is None:\n",
        "        print(\"‚ùå Heart model, scaler, or feature columns not loaded\")\n",
        "        return np.array([[0.5, 0.5]])  # Neutral default\n",
        "\n",
        "    # If input is a file path, load CSV\n",
        "    if isinstance(input_data, str):\n",
        "        heart_df = pd.read_csv(input_data)\n",
        "    else:\n",
        "        heart_df = input_data.copy()\n",
        "\n",
        "    # Drop unnecessary columns but keep 'Unnamed: 0' if it exists\n",
        "    columns_to_drop = ['Unnamed: 0', 'id', 'num', 'label']\n",
        "    X_heart = heart_df.drop(columns=[col for col in columns_to_drop if col in heart_df.columns], errors='ignore')\n",
        "\n",
        "    # Align with training columns\n",
        "    for col in heart_feature_cols:\n",
        "        if col not in X_heart.columns:\n",
        "            X_heart[col] = 0\n",
        "    X_heart = X_heart[heart_feature_cols]\n",
        "\n",
        "    # Apply scaling\n",
        "    X_heart = heart_scaler.transform(X_heart)\n",
        "\n",
        "    # Load model and predict\n",
        "    probs = heart_model.predict_proba(X_heart)\n",
        "    return probs\n",
        "\n",
        "print(\"‚úÖ Heart disease prediction function defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ X-ray prediction function defined\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# ü´Å X-ray Prediction Function\n",
        "# ============================================\n",
        "\n",
        "# Define a simple CNN model architecture (should match the training model)\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, padding=1)  # Grayscale input\n",
        "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(16 * 56 * 56, num_classes)  # 224x224 -> 56x56 after pooling\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.max_pool2d(x, 2)\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = torch.max_pool2d(x, 2)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "def predict_xray(image_path):\n",
        "    \"\"\"\n",
        "    Predicts pneumonia from chest X-ray image using the trained CNN model.\n",
        "    Returns probabilities for [Normal, Pneumonia]\n",
        "    \"\"\"\n",
        "    if xray_state_dict is None:\n",
        "        print(\"‚ùå X-ray model not loaded\")\n",
        "        return np.array([[0.5, 0.5]])  # Neutral default\n",
        "        \n",
        "    try:\n",
        "        # Create model instance\n",
        "        model = SimpleCNN(num_classes=2)\n",
        "        \n",
        "        # Load the trained model state dict\n",
        "        model.load_state_dict(xray_state_dict)\n",
        "        model.eval()\n",
        "        \n",
        "        # Define transforms (grayscale for this model)\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.Grayscale(num_output_channels=1),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "        \n",
        "        # Load and preprocess image\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        image_tensor = transform(image).unsqueeze(0)\n",
        "        \n",
        "        # Make prediction\n",
        "        with torch.no_grad():\n",
        "            outputs = model(image_tensor)\n",
        "            probabilities = torch.softmax(outputs, dim=1)\n",
        "            \n",
        "        return probabilities.numpy()\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error in X-ray prediction: {e}\")\n",
        "        # Return neutral probabilities if prediction fails\n",
        "        return np.array([[0.5, 0.5]])\n",
        "\n",
        "print(\"‚úÖ X-ray prediction function defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Ensemble prediction functions defined\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# üß© Unified Ensemble (Multimodal Fusion)\n",
        "# ============================================\n",
        "\n",
        "def map_binary_to_multiclass(symptom_probs, heart_probs, xray_probs, label_names):\n",
        "    \"\"\"\n",
        "    Maps binary heart/xray outputs into 24-class probabilities.\n",
        "    Adds small weight contributions to relevant classes.\n",
        "    \"\"\"\n",
        "    final_probs = symptom_probs.copy()\n",
        "\n",
        "    # Extract relevant probabilities\n",
        "    heart_disease_prob = heart_probs[0, 1] if heart_probs.size > 0 else 0\n",
        "    pneumonia_prob = xray_probs[0, 1] if xray_probs.size > 0 else 0\n",
        "\n",
        "    # Add contributions to mapped diseases\n",
        "    if \"Hypertension\" in label_names:\n",
        "        idx = label_names.index(\"Hypertension\")\n",
        "        final_probs[0, idx] += 0.3 * heart_disease_prob\n",
        "\n",
        "    if \"Pneumonia\" in label_names:\n",
        "        idx = label_names.index(\"Pneumonia\")\n",
        "        final_probs[0, idx] += 0.4 * pneumonia_prob\n",
        "\n",
        "    # Normalize back to probabilities\n",
        "    final_probs = final_probs / final_probs.sum(axis=1, keepdims=True)\n",
        "    return final_probs\n",
        "\n",
        "\n",
        "def final_multimodal_prediction(symptom_text, heart_row, xray_path, label_names):\n",
        "    \"\"\"\n",
        "    Combines all three models for final prediction\n",
        "    \"\"\"\n",
        "    symptom_pred = predict_symptoms([symptom_text])\n",
        "    heart_pred = predict_heart(heart_row)\n",
        "    xray_pred = predict_xray(xray_path)\n",
        "\n",
        "    if len(symptom_pred) == 0:\n",
        "        raise ValueError(\"Symptom model failed.\")\n",
        "    if len(heart_pred) == 0:\n",
        "        heart_pred = np.array([[0.5, 0.5]])  # Neutral default\n",
        "    if len(xray_pred) == 0:\n",
        "        xray_pred = np.array([[0.5, 0.5]])\n",
        "\n",
        "    combined_probs = map_binary_to_multiclass(symptom_pred, heart_pred, xray_pred, label_names)\n",
        "    final_label = label_names[np.argmax(combined_probs)]\n",
        "    return final_label, combined_probs\n",
        "\n",
        "print(\"‚úÖ Ensemble prediction functions defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ Testing the loaded models...\n",
            "‚úÖ Symptom prediction: (1, 24)\n",
            "‚úÖ Heart prediction: (1, 2)\n",
            "‚úÖ X-ray prediction: (1, 2)\n",
            "\n",
            "üéâ All available models tested successfully!\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# üß™ Test the Loaded Models\n",
        "# ============================================\n",
        "\n",
        "print(\"üß™ Testing the loaded models...\")\n",
        "\n",
        "# Test individual models\n",
        "try:\n",
        "    # Test symptom prediction\n",
        "    test_symptoms = [\"chest pain and shortness of breath\"]\n",
        "    symptom_probs = predict_symptoms(test_symptoms)\n",
        "    print(f\"‚úÖ Symptom prediction: {symptom_probs.shape}\")\n",
        "    \n",
        "    # Test heart prediction\n",
        "    if os.path.exists(\"pre_heart.csv\"):\n",
        "        test_heart = pd.read_csv(\"pre_heart.csv\").iloc[[0]]\n",
        "        heart_probs = predict_heart(test_heart)\n",
        "        print(f\"‚úÖ Heart prediction: {heart_probs.shape}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è pre_heart.csv not found, skipping heart test\")\n",
        "    \n",
        "    # Test X-ray prediction (if file exists)\n",
        "    xray_path = os.path.join(\"data\", \"raw\", \"chest_xray\", \"chest_xray\", \"val\", \"NORMAL\", \"NORMAL2-IM-1427-0001.jpeg\")\n",
        "    if os.path.exists(xray_path):\n",
        "        xray_probs = predict_xray(xray_path)\n",
        "        print(f\"‚úÖ X-ray prediction: {xray_probs.shape}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è X-ray file not found, skipping X-ray test\")\n",
        "    \n",
        "    print(\"\\nüéâ All available models tested successfully!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error during testing: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ Running complete multimodal prediction example...\n",
            "\n",
            "ü©∫ Final Disease Prediction: Pneumonia\n",
            "üìä Prediction Probabilities:\n",
            "  1. Pneumonia: 0.2705\n",
            "  2. Dimorphic Hemorrhoids: 0.1572\n",
            "  3. Hypertension: 0.0983\n",
            "  4. drug reaction: 0.0768\n",
            "  5. gastroesophageal reflux disease: 0.0545\n",
            "\n",
            "‚úÖ Complete prediction example successful!\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# üéØ Example Usage - Complete Prediction\n",
        "# ============================================\n",
        "\n",
        "print(\"üéØ Running complete multimodal prediction example...\")\n",
        "\n",
        "try:\n",
        "    # Example inputs\n",
        "    symptom_text = \"Chest pain and shortness of breath\"\n",
        "    \n",
        "    # Load heart data if available\n",
        "    if os.path.exists(\"pre_heart.csv\"):\n",
        "        heart_row = pd.read_csv(\"pre_heart.csv\").iloc[[0]]\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Using dummy heart data\")\n",
        "        heart_row = pd.DataFrame([[0] * 30])  # Dummy data\n",
        "    \n",
        "    # X-ray path\n",
        "    xray_path = os.path.join(\"data\", \"raw\", \"chest_xray\", \"chest_xray\", \"val\", \"NORMAL\", \"NORMAL2-IM-1427-0001.jpeg\")\n",
        "    \n",
        "    # Run complete prediction\n",
        "    prediction, probs = final_multimodal_prediction(symptom_text, heart_row, xray_path, label_names)\n",
        "    \n",
        "    print(f\"\\nü©∫ Final Disease Prediction: {prediction}\")\n",
        "    print(f\"üìä Prediction Probabilities:\")\n",
        "    \n",
        "    # Show top 5 predictions\n",
        "    top_indices = np.argsort(probs[0])[-5:][::-1]\n",
        "    for i, idx in enumerate(top_indices):\n",
        "        print(f\"  {i+1}. {label_names[idx]}: {probs[0][idx]:.4f}\")\n",
        "    \n",
        "    print(\"\\n‚úÖ Complete prediction example successful!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error in complete prediction: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nltk_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
